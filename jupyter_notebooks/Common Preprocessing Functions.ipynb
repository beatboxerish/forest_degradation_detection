{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a726541",
   "metadata": {},
   "source": [
    "This notebook primarily deals with creation of preprocessing functions that contain code to preprocess vectors and rasters. Heavy notebook. Loads of functions and code. \n",
    "\n",
    "Go section by section. Read the description of the section for sure before you decide to run anything.\n",
    "\n",
    "Necessary libraries might have to be manually installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52adbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# the below might not be installed already for you in your local installation\n",
    "from osgeo import gdal\n",
    "from geojson import Polygon, Feature, FeatureCollection, dump\n",
    "import rasterio as rio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from haversine import haversine, Unit\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "from rasterio import transform, features\n",
    "from rasterio.plot import show\n",
    "\n",
    "from area import area\n",
    "\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc508400",
   "metadata": {},
   "source": [
    "### To Convert CRS\n",
    "\n",
    "Use the below low level function or simply use **rio.warp.transform_bounds()**. This helps us convert the CRS of a raster to a specific CRS.\n",
    "\n",
    "Completely independent function. Don't need to run anything before this step or after this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open TIFF file and define path to save new TIFF file\n",
    "tif_path = '/Users/ishannangia/Desktop/TfW/tifs and labels/new_dryDeciduousSite.tif'\n",
    "output_tif_path = '/Users/ishannangia/Desktop/TfW/tifs and labels/new_dryDeciduousSite.tif'\n",
    "\n",
    "dataset = rio.open(tif_path)\n",
    "data_to_transform = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6effeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input destination CRS and display current CRS\n",
    "# destination CRS\n",
    "dst_crs = 'EPSG:4326'\n",
    "# dst_crs = 'EPSG:32643'\n",
    "\n",
    "# display current CRS\n",
    "data_to_transform.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cf407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating transform along with other parameters for conversion\n",
    "transform, width, height = calculate_default_transform(data_to_transform.crs, dst_crs, \n",
    "                                                       data_to_transform.width, data_to_transform.height, \n",
    "                                                       *data_to_transform.bounds)\n",
    "\n",
    "new_kwargs = data_to_transform.meta.copy()\n",
    "new_kwargs.update({\n",
    "    'crs': dst_crs,\n",
    "    'transform': transform,\n",
    "    'width': width,\n",
    "    'height': height\n",
    "})\n",
    "\n",
    "# implementing the reprojection\n",
    "with rio.open(output_tif_path, 'w', **new_kwargs) as dst:\n",
    "    for i in range(1, data_to_transform.count + 1):\n",
    "        reproject(\n",
    "            source=rio.band(data_to_transform, i),\n",
    "            destination=rio.band(dst, i),\n",
    "            src_transform=data_to_transform.transform,\n",
    "            src_crs=data_to_transform.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae33dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check: open new data and check what values the transformed edge of image coordinates show\n",
    "transformed_data = rio.open(output_tif_path)\n",
    "transformed_data.transform * (transformed_data.width, transformed_data.height) # longitude, latitude format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dfbe2c",
   "metadata": {},
   "source": [
    "### Finding the Extent of the Raster\n",
    "\n",
    "Finding the size of the area covered by the raster, if the raster has \"epsg 4326\" as the CRS.\n",
    "\n",
    "Completely independent function. Don't need to run anything before this step or after this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extent_in_meters_raster(ds):\n",
    "    left, bottom, right, top = ds.bounds\n",
    "    # (lat, long format)\n",
    "    ul = top, left\n",
    "    ur = top, right\n",
    "    bl = bottom, left\n",
    "    br = bottom, right\n",
    "\n",
    "    ul_to_ur = haversine(ul, ur, unit=Unit.METERS)\n",
    "    bl_to_br = haversine(bl, br, unit=Unit.METERS)\n",
    "    ul_to_bl = haversine(ul, bl, unit=Unit.METERS)\n",
    "    ur_to_br = haversine(ur, br, unit=Unit.METERS)\n",
    "    return ul_to_ur, bl_to_br, ul_to_bl, ur_to_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input TIFF path\n",
    "tif_path_extent = './del_this_full.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbaec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the dataset and check CRS\n",
    "extent_dataset = rio.open(tif_path_extent)\n",
    "extent_dataset.crs.data[\"init\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65cde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distances between corner coordinates\n",
    "ul_to_ur, bl_to_br, ul_to_bl, ur_to_br = get_extent_in_meters_raster(extent_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa69f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c5b7c",
   "metadata": {},
   "source": [
    "### For Splitting TIF Files\n",
    "\n",
    "Here, we split TIFF files into smaller TIFF files with a predefined pixel height and width.\n",
    "\n",
    "Completely independent function. Don't need to run anything before this step or after this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec913a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining TIFF and paths\n",
    "input_tif = '../../Desktop/TfW/tifs and labels/new_dryDeciduousSite.tif'\n",
    "output_path = '../../Desktop/TfW/tifs and labels/dryDeciduousSite_tifs/'\n",
    "main_file_suffix = 'dryDeciduousSite'\n",
    "\n",
    "gdal_dataset = gdal.Open(input_tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc331ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining destination smaller image (tile) size in pixels\n",
    "tile_size_x = 640 * 3 # in pixels\n",
    "tile_size_y = tile_size_x\n",
    "\n",
    "band = gdal_dataset.GetRasterBand(1)\n",
    "xsize = band.XSize\n",
    "ysize = band.YSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b246480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for creating all smaller tifs using one larger tif given above parameters\n",
    "for i in range(0, xsize+tile_size_x, tile_size_x):\n",
    "    for j in range(0, ysize+tile_size_y, tile_size_y):\n",
    "        current_file_name = f\"{str(main_file_suffix)}_x_{str(i)}_y_{str(j)}.tif\"\n",
    "        output_file_path = os.path.join(output_path, current_file_name)\n",
    "        _ = gdal.Translate(output_file_path, gdal_dataset, srcWin=[i, j, tile_size_x, tile_size_y])\n",
    "        \n",
    "        #### todo: be a little careful of this code\n",
    "        unique_mask_values = np.unique(_.GetRasterBand(4).ReadAsArray())\n",
    "        if (len(unique_mask_values) == 1) and (unique_mask_values[0]==0):\n",
    "            os.remove(output_file_path)\n",
    "        _.Close() ### needed for viewing and actually working with the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ef910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### code for creating a single mini TIF file\n",
    "\n",
    "# center_x = 2000\n",
    "# center_y = 2000\n",
    "# tile_size_x = 640 * 3\n",
    "# tile_size_y = tile_size_x\n",
    "\n",
    "# band = gdal_dataset.GetRasterBand(1)\n",
    "# xsize = band.XSize\n",
    "# ysize = band.YSize\n",
    "\n",
    "# _ = gdal.Translate(output_path, gdal_dataset, srcWin=[center_x, center_y, tile_size_x, tile_size_y])\n",
    "# _.Close() ### needed for viewing and actually working with the file\n",
    "\n",
    "### checking the output\n",
    "# small_dataset = rio.open(output_path)\n",
    "# plt.imshow(np.moveaxis(small_dataset.read([1,2,3]), 0, 2))\n",
    "\n",
    "# # getting sizes\n",
    "# ul_to_ur, bl_to_br, ul_to_bl, ur_to_br = get_extent_in_meters_raster(small_dataset)\n",
    "\n",
    "# print(ul_to_ur, ul_to_bl)\n",
    "# small_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a1007",
   "metadata": {},
   "source": [
    "## Converting LabelMe Annotations to Final Vector Files\n",
    "\n",
    "This section allows you to create vector geojson files from LabelMe annotations that you either have created by manually labelling or created via the prediction outputs of some segmentation model.\n",
    "\n",
    "There are three mini-sections here. All follow each other in the order that is given here and can't be run independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f2aa2",
   "metadata": {},
   "source": [
    "### 1. Converting Individual Labelme Labels to Individual Geojson Files\n",
    "\n",
    "This code helps in converting labelme labels to geojsons/vectors that can be used to downstream when working with the satellite model.\n",
    "\n",
    "Not a completely independent snippet/section. Post running this you should run the next snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbcecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this block if one has predefined sites where labelme annotations are kept in folders\n",
    "# each site has a folder called sitename_tifs inside which jsons are kept\n",
    "\n",
    "sites = [\"burntSite\", \"restorationSite\", \"chromoStrobeSite\", \"plantationSite\"]\n",
    "\n",
    "for site in sites:\n",
    "    main_address = f\"/Users/Ishannangia/Desktop/TfW/tifs and labels/{site}_tifs\"\n",
    "    for geojson in glob(os.path.join(main_address, \"*.geojson\"):\n",
    "        os.remove(geojson)\n",
    "        \n",
    "    all_jsons = glob(os.path.join(main_address, \"*.json\"))\n",
    "\n",
    "    for json_file in all_jsons:\n",
    "        name_of_file = json_file.split(\".\")[-2]\n",
    "        name_of_tif = name_of_file + '.tif'\n",
    "\n",
    "        with open(json_file, \"r\") as file:\n",
    "            f = json.load(file)\n",
    "\n",
    "        ds = rio.open(name_of_tif)\n",
    "\n",
    "        all_polys = {}\n",
    "        for polygon in f['shapes']:\n",
    "            pts = []\n",
    "            name = polygon['label']\n",
    "            for point in polygon['points']:\n",
    "                pt = ds.transform * (point[0], point[1])\n",
    "                pts.append(pt)\n",
    "            current_poly = Polygon([pts])\n",
    "            try:\n",
    "                all_polys[name].append(Feature(geometry=current_poly, properties= {\"name\": name}))\n",
    "            except:\n",
    "                all_polys[name] = [Feature(geometry=current_poly, properties= {\"name\": name})]\n",
    "\n",
    "        for i, j in all_polys.items():\n",
    "            feature_collection = FeatureCollection(j)\n",
    "            with open(f'{name_of_file}_{i}.geojson', 'w') as f:\n",
    "                dump(feature_collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec63923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this block if you just have a single folder in which jsons are kept along with tiff files used in the labelme\n",
    "# labelling procedure\n",
    "\n",
    "main_address = f\"/Users/Ishannangia/Desktop/three_dis_labelme_files\"\n",
    "\n",
    "for geojson in glob(os.path.join(main_address, \"*.geojson\")):\n",
    "    os.remove(geojson)\n",
    "\n",
    "all_jsons = glob(os.path.join(main_address, \"*.json\"))\n",
    "\n",
    "for json_file in all_jsons:\n",
    "    name_of_file = json_file.split(\".\")[-2]\n",
    "    name_of_tif = name_of_file + '.tif'\n",
    "\n",
    "    with open(json_file, \"r\") as file:\n",
    "        f = json.load(file)\n",
    "\n",
    "    ds = rio.open(name_of_tif)\n",
    "\n",
    "    all_polys = {}\n",
    "    for polygon in f['shapes']:\n",
    "        pts = []\n",
    "        name = polygon['label']\n",
    "        for point in polygon['points']:\n",
    "            pt = ds.transform * (point[0], point[1])\n",
    "            pts.append(pt)\n",
    "        current_poly = Polygon([pts])\n",
    "        try:\n",
    "            all_polys[name].append(Feature(geometry=current_poly, properties= {\"name\": name}))\n",
    "        except:\n",
    "            all_polys[name] = [Feature(geometry=current_poly, properties= {\"name\": name})]\n",
    "\n",
    "    for i, j in all_polys.items():\n",
    "        feature_collection = FeatureCollection(j)\n",
    "        with open(f'{name_of_file}_{i}.geojson', 'w') as f:\n",
    "            dump(feature_collection, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d668c9",
   "metadata": {},
   "source": [
    "### 2. Combining all GeoJSONs Together\n",
    "\n",
    "The above step produces an individual geojson/vector file for each labelme annotation file/image present in the given dir. This step combines all the individual geojsons together to create a single geojson for each degradation indicator that is present in the given folder.\n",
    "\n",
    "Not a completely independent snippet/section. This should only be run on the outputs of the previous snippet. Post running this you should run the next snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here label_dict should be changed to change mapping of degradation indicators from how it is labelled currently\n",
    "# to what is needed in the output geojsons. Consider our 4 DI and 3 DI cases.\n",
    "\n",
    "# run this block if one has predefined sites and the first code block from the above step has been run.\n",
    "\n",
    "\n",
    "label_dict = {\n",
    "    \"Distorted Image\": \"Distorted Image\",\n",
    "    'Canopy Gap: Shaded': 'Canopy Gap: Shaded',\n",
    "    'Canopy Gap: Vegetated': 'Canopy Gap: Vegetated',\n",
    "    \"Canopy Gap: Bare Land\": 'Canopy Gap: Bare Land',\n",
    "    'Plantation': 'Plantation',\n",
    "    'Potential Invasive': 'Potential Invasive',\n",
    "    'Potential Creeper': 'Potential Creeper',\n",
    "    'Cane': 'Cane'\n",
    "}\n",
    "\n",
    "cat_dict = dict()\n",
    "\n",
    "for site in sites:\n",
    "    input_folder = f\"/Users/Ishannangia/Desktop/TfW/tifs and labels/{site}_tifs/\"\n",
    "    all_geojsons = glob(os.path.join(input_folder, '*.geojson')) ## collect all geojsons from that folder\n",
    "    geojson_categories = [file_name.split('.')[-2].split('/')[-1].split('_')[-1] for file_name in all_geojsons]\n",
    "    unique_categories = set(geojson_categories)\n",
    "    \n",
    "    print('For site:', site)\n",
    "    \n",
    "    for category in unique_categories:\n",
    "        try:\n",
    "            converted_cat = label_dict[category]\n",
    "        except:\n",
    "            continue\n",
    "        cat_features = []\n",
    "        \n",
    "        for idx, file_cat in enumerate(geojson_categories):\n",
    "            if file_cat == category: \n",
    "                with open(all_geojsons[idx], \"r\") as file:\n",
    "                    f = json.load(file)\n",
    "                cat_features.extend(f[\"features\"])\n",
    "                \n",
    "        feature_collection = FeatureCollection(cat_features)\n",
    "        with open(f'{os.path.join(input_folder, converted_cat)}_{site}.geojson', 'w') as f:\n",
    "            dump(feature_collection, f)\n",
    "            \n",
    "        print(category)\n",
    "        print(\"Converted to:\", converted_cat)\n",
    "        print(\"Number of Polygons:\", len(cat_features))\n",
    "        \n",
    "        try:\n",
    "            cat_dict[converted_cat].extend(areas)\n",
    "        except:\n",
    "            cat_dict[converted_cat] = areas\n",
    "\n",
    "        # get area stats\n",
    "        areas = [area(feat[\"geometry\"]) for feat in cat_features]\n",
    "        print(\"\\nAREA STATS (in sq. metres)\")\n",
    "        print('Min:', min(areas))\n",
    "        print('Max:', max(areas))\n",
    "        print('Mean:', np.mean(areas))\n",
    "        print('Std. Deviation:', np.std(areas))\n",
    "        for q in np.arange(10, 100, 20):\n",
    "            print(f\"{q}th percentile:\", np.percentile(areas, q))\n",
    "        plt.hist(areas, bins=20)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.xlabel(\"Size of Polygon\")\n",
    "        plt.title(f'Histogram for {converted_cat}')\n",
    "        plt.show()\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df298a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here label_dict should be changed to change mapping of degradation indicators from how it is labelled currently\n",
    "# to what is needed in the output geojsons. Consider our 4 DI and 3 DI cases.\n",
    "\n",
    "# run this block if one doesn't have predefined sites and only one single folder where geojsons are present\n",
    "# the second code block from the above step should be run for prepping the files for this step\n",
    "\n",
    "input_folder = f\"/Users/Ishannangia/Desktop/three_dis_labelme_files\"\n",
    "\n",
    "label_dict = {\n",
    "    \"Distorted Image\": \"Distorted Image\",\n",
    "    'Canopy Gap: Shaded': 'Canopy Gap: Shaded',\n",
    "    'Canopy Gap: Vegetated': 'Canopy Gap: Vegetated',\n",
    "    \"Canopy Gap: Bare Land\": 'Canopy Gap: Bare Land',\n",
    "    'Plantation': 'Plantation',\n",
    "#     'Potential Invasive': 'Potential Invasive',\n",
    "#     'Potential Creeper': 'Potential Creeper',\n",
    "#     'Cane': 'Cane'\n",
    "}\n",
    "\n",
    "label_dict = {\n",
    "    \"Distorted Image\": \"Distorted Image\",\n",
    "    \"Bare Land\": 'Bare Land',\n",
    "    \"Canopy Gap\": 'Canopy Gap',\n",
    "    \"Plantation\": 'Plantation',\n",
    "}\n",
    "\n",
    "cat_dict = dict()\n",
    "\n",
    "all_geojsons = glob(os.path.join(input_folder, '*.geojson')) ## collect all geojsons from that folder\n",
    "geojson_categories = [file_name.split('.')[-2].split('/')[-1].split('_')[-1] for file_name in all_geojsons]\n",
    "unique_categories = set(geojson_categories)\n",
    "\n",
    "\n",
    "for category in unique_categories:\n",
    "    try:\n",
    "        converted_cat = label_dict[category]\n",
    "    except:\n",
    "        continue\n",
    "    cat_features = []\n",
    "\n",
    "    for idx, file_cat in enumerate(geojson_categories):\n",
    "        if file_cat == category: \n",
    "            with open(all_geojsons[idx], \"r\") as file:\n",
    "                f = json.load(file)\n",
    "            cat_features.extend(f[\"features\"])\n",
    "\n",
    "    feature_collection = FeatureCollection(cat_features)\n",
    "    with open(f'{os.path.join(input_folder, converted_cat)}.geojson', 'w') as f:\n",
    "        dump(feature_collection, f)\n",
    "\n",
    "#     print(category)\n",
    "#     print(\"Converted to:\", converted_cat)\n",
    "#     print(\"Number of Polygons:\", len(cat_features))\n",
    "\n",
    "#     try:\n",
    "#         cat_dict[converted_cat].extend(areas)\n",
    "#     except:\n",
    "#         cat_dict[converted_cat] = areas\n",
    "\n",
    "#     # get area stats\n",
    "#     areas = [area(feat[\"geometry\"]) for feat in cat_features]\n",
    "#     print(\"\\nAREA STATS (in sq. metres)\")\n",
    "#     print('Min:', min(areas))\n",
    "#     print('Max:', max(areas))\n",
    "#     print('Mean:', np.mean(areas))\n",
    "#     print('Std. Deviation:', np.std(areas))\n",
    "#     for q in np.arange(10, 100, 20):\n",
    "#         print(f\"{q}th percentile:\", np.percentile(areas, q))\n",
    "#     plt.hist(areas, bins=20)\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.xlabel(\"Size of Polygon\")\n",
    "#     plt.title(f'Histogram for {converted_cat}')\n",
    "#     plt.show()\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c683b9b",
   "metadata": {},
   "source": [
    "### 3. Combine all Category GeoJSONs Together\n",
    "\n",
    "This step combines all geojsons of different categories to create one single geojson. Needs the above code block to run before this is run.\n",
    "\n",
    "Not a completely independent snippet/section. This should only be run on the outputs of the previous snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = f\"/Users/Ishannangia/Desktop/three_dis_labelme_files\"\n",
    "\n",
    "label_dict = {\n",
    "    \"Distorted Image\": \"Distorted Image\",\n",
    "    \"Bare Land\": 'Bare Land',\n",
    "    \"Canopy Gap\": 'Canopy Gap',\n",
    "    \"Plantation\": 'Plantation',\n",
    "}\n",
    "\n",
    "\n",
    "main_dict = {'type': 'FeatureCollection',\n",
    "             'features':[]}\n",
    "all_geojsons = []\n",
    "\n",
    "# collect all geojsons w.r.t. the categories/degradation indicators that have been defined\n",
    "for k, v in label_dict.items():\n",
    "    all_geojsons.append(os.path.join(input_folder, \n",
    "                                     f'{v}.geojson'))\n",
    "    \n",
    "# create one geojson using all geojsons\n",
    "for geojson in all_geojsons:\n",
    "    try:\n",
    "        with open(geojson, \"r\") as file:\n",
    "            f = json.load(file)\n",
    "        main_dict['features'].extend(f[\"features\"])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "with open(os.path.join(input_folder, \"final.geojson\"), 'w') as f:\n",
    "    dump(main_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37033e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(input_folder, \"final.geojson\"), \"r\") as file:\n",
    "#     f = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e2ad9",
   "metadata": {},
   "source": [
    "### Converting Vectors to Rasters\n",
    "\n",
    "Converts vector files to raster files\n",
    "\n",
    "Completely independenet section. Can be run without any dependence on other snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_data_for_transform(extent_file_path, res):\n",
    "    extent_file = gpd.read_file(extent_file_path)\n",
    "    bbox = extent_file.total_bounds\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "\n",
    "    w = (xmax - xmin) // res\n",
    "    h = (ymax - ymin) // res\n",
    "\n",
    "    out_meta = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"dtype\": \"uint8\",\n",
    "        \"height\": h,\n",
    "        \"width\": w,\n",
    "        \"count\": 1,\n",
    "        \"crs\": extent_file.crs,\n",
    "        \"transform\": transform.from_bounds(xmin, ymin, xmax, ymax, w, h),\n",
    "        \"compress\": 'lzw'\n",
    "    }\n",
    "    return out_meta\n",
    "\n",
    "\n",
    "def map_name_to_class(x):\n",
    "    if 'Vegetated' in x:\n",
    "        return 1\n",
    "    elif 'Shaded' in x:\n",
    "        return 2\n",
    "    elif 'Bare' in x:\n",
    "        return 3\n",
    "    \n",
    "    \n",
    "def get_resolution_from_resolution_file_path(res_file_path):\n",
    "    ds = rio.open(res_file_path)\n",
    "    pixel_size_x, pixel_size_y = ds.res\n",
    "    return pixel_size_x, pixel_size_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e65d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_names = [\"/Users/ishannangia/Desktop/TfW/tifs and labels/burntSite_tifs/Canopy Gap: Bare Land.geojson\",\n",
    "                \"/Users/ishannangia/Desktop/TfW/tifs and labels/burntSite_tifs/Canopy Gap: Shaded.geojson\",\n",
    "                \"/Users/ishannangia/Desktop/TfW/tifs and labels/burntSite_tifs/Canopy Gap: Vegetated.geojson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_list = []\n",
    "for vector_name in vector_names:\n",
    "    gdf = gpd.read_file(vector_name)\n",
    "    gdf_list.append(gdf)\n",
    "    \n",
    "main_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))\n",
    "main_gdf['classes'] = main_gdf.name.apply(map_name_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent_file_path = \"../../Desktop/TfW/MhadeiAoi/MhadeiAoi.shp\"\n",
    "output_raster_path = \"del_this_raster.tif\"\n",
    "res_file_path = \"/Users/ishannangia/Desktop/TfW/tifs and labels/restorationSite.tif\"\n",
    "\n",
    "res = 0.00001 # desired resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size_x, pixel_size_y = get_resolution_from_resolution_file_path(res_file_path)\n",
    "res = pixel_size_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa570bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_meta = get_meta_data_for_transform(extent_file_path, res)\n",
    "\n",
    "with rio.open(output_raster_path, 'w+', **out_meta) as out:\n",
    "    out_arr = out.read(1)\n",
    "\n",
    "    # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "    shapes = ((geom, value) for geom, value in zip(main_gdf.geometry, main_gdf.classes))\n",
    "\n",
    "    burned = features.rasterize(shapes=shapes, fill=0, out=out_arr, transform=out.transform)\n",
    "    out.write_band(1, burned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5cc085",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out_meta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rio.open(output_raster_path)\n",
    "dataset = rio.open('/Users/ishannangia/github_repos/Mhadei_Restoration/results/vec2raster.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (satImagery)",
   "language": "python",
   "name": "satimagery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
