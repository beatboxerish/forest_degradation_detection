{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Wg1a82_PEf2N"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "OYZqRJyvN2xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import os\n",
        "import shutil\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "UEwAuTkmE4f6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### general_utils\n",
        "def open_yaml_file(yaml_address):\n",
        "    with open(yaml_address, 'r') as infile:\n",
        "        yaml_file = yaml.load(infile, Loader=yaml.SafeLoader)\n",
        "    return yaml_file\n",
        "\n",
        "\n",
        "def save_yaml_file(yaml_file, save_yaml_address):\n",
        "    with open(save_yaml_address, 'w') as outfile:\n",
        "        yaml.dump(yaml_file, outfile, default_flow_style=False)"
      ],
      "metadata": {
        "id": "dDO-z9hmOE_J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### train_utils\n",
        "def train_model(model,\n",
        "                n_epochs,\n",
        "                data_yaml_address,\n",
        "                imgsz=640,\n",
        "                patience=0,\n",
        "                device=None,\n",
        "                batch=16,\n",
        "                aug_dict={}):\n",
        "    results = model.train(data=data_yaml_address, epochs=n_epochs, imgsz=imgsz, patience=patience,\n",
        "                          device=device, batch=batch, **augmentation_dict)\n",
        "    return results\n",
        "\n",
        "\n",
        "def load_yolo(model_address):\n",
        "    model = YOLO(model_address)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Fx1YZ3ECNw76"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### extra_utils\n",
        "def change_data_yaml_dataset_locations(yaml_path, new_root_path):\n",
        "    \"\"\"\n",
        "    Using this function to rectify addresses in data.yaml since\n",
        "    it would contain addresses corresponding to our local directories\n",
        "    instead of colab-specific addresses.\n",
        "    \"\"\"\n",
        "\n",
        "    yaml_file = open_yaml_file(yaml_path)\n",
        "    for data_type in ['train', 'test', 'val']:\n",
        "        yaml_file[data_type] = os.path.join(new_root_path,\n",
        "                                            data_type)\n",
        "    save_yaml_file(yaml_file, yaml_path)\n",
        "    return None"
      ],
      "metadata": {
        "id": "Q2xgNZyoPgKV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifying dataset location"
      ],
      "metadata": {
        "id": "WphEKLHoE7sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = \"/content/drive/MyDrive/Mhadei Restoration Research/Data for ML Work/Yolo-4\"\n",
        "yaml_path = os.path.join(root_path, \"data.yaml\")\n",
        "\n",
        "change_data_yaml_dataset_locations(yaml_path, root_path)"
      ],
      "metadata": {
        "id": "B0X0QfyaQK66"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifying augmentation dict"
      ],
      "metadata": {
        "id": "ml57u0GWE-qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation_dict = {\n",
        "    \"hsv_h\": 0.75, # (float) image HSV-Hue augmentation (fraction)\n",
        "    \"hsv_s\": 1, # (float) image HSV-Saturation augmentation (fraction)\n",
        "    \"hsv_v\": 0.25, # (float) image HSV-Value augmentation (fraction)\n",
        "    \"translate\": 0.1, # (float) image translation (+/- fraction)\n",
        "    \"degrees\": 10, # (float) image rotation (+/- deg)\n",
        "    \"scale\": 0.1, # (float) image scale (+/- gain)\n",
        "    \"shear\": 30, # (float) image shear (+/- deg)\n",
        "    \"perspective\": 0.0, # (float) image perspective (+/- fraction), range 0-0.001\n",
        "    \"flipud\": 0.5, # (float) image flip up-down (probability)\n",
        "    \"fliplr\": 0.5, # (float) image flip left-right (probability)\n",
        "    \"bgr\": 0.0, # (float) image channel BGR (probability)\n",
        "    \"mosaic\": 0.5, # (float) image mosaic (probability)\n",
        "    \"mixup\": 0.5, # (float) image mixup (probability)\n",
        "    \"copy_paste\": 0.0, # (float) segment copy-paste (probability)\n",
        "    \"auto_augment\": \"randaugment\", # (str) auto augmentation policy for classification (randaugment, autoaugment, augmix)\n",
        "    \"erasing\": 0, # (float) probability of random erasing during classification training (0-0.9), 0 means no erasing, must be less than 1.0.\n",
        "    \"crop_fraction\": 1.0, # (float) image crop fraction for classification (0.1-1), 1.0 means no crop, must be greater than 0.\n",
        "}\n",
        "\n",
        "no_augmentation_dict = {\n",
        "    \"hsv_h\": 0, # (float) image HSV-Hue augmentation (fraction)\n",
        "    \"hsv_s\": 0, # (float) image HSV-Saturation augmentation (fraction)\n",
        "    \"hsv_v\": 0, # (float) image HSV-Value augmentation (fraction)\n",
        "    \"translate\": 0, # (float) image translation (+/- fraction)\n",
        "    \"degrees\": 0, # (float) image rotation (+/- deg)\n",
        "    \"scale\": 0, # (float) image scale (+/- gain)\n",
        "    \"shear\": 0, # (float) image shear (+/- deg)\n",
        "    \"perspective\": 0.0, # (float) image perspective (+/- fraction), range 0-0.001\n",
        "    \"flipud\": 0, # (float) image flip up-down (probability)\n",
        "    \"fliplr\": 0, # (float) image flip left-right (probability)\n",
        "    \"bgr\": 0.0, # (float) image channel BGR (probability)\n",
        "    \"mosaic\": 0, # (float) image mosaic (probability)\n",
        "    \"mixup\": 0, # (float) image mixup (probability)\n",
        "    \"copy_paste\": 0.0, # (float) segment copy-paste (probability)\n",
        "    \"auto_augment\": \"randaugment\", # (str) auto augmentation policy for classification (randaugment, autoaugment, augmix)\n",
        "    \"erasing\": 0, # (float) probability of random erasing during classification training (0-0.9), 0 means no erasing, must be less than 1.0.\n",
        "    \"crop_fraction\": 1.0, # (float) image crop fraction for classification (0.1-1), 1.0 means no crop, must be greater than 0.\n",
        "}"
      ],
      "metadata": {
        "id": "FlCoobwKBcV2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "UemLl4kQFEMX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeFQJNYlNgbf"
      },
      "outputs": [],
      "source": [
        "train_parameter_dict = {\n",
        "    \"n_epochs\": 1000,\n",
        "    \"imgsz\": 640,\n",
        "    \"data_yaml_address\": yaml_path,\n",
        "    'patience': 0,\n",
        "    'device': None,\n",
        "    'batch': 8\n",
        "}\n",
        "\n",
        "yolo_address = \"yolov8m-seg.pt\"\n",
        "\n",
        "# load a model\n",
        "model = load_yolo(yolo_address)\n",
        "\n",
        "# train a model\n",
        "results = train_model(model,\n",
        "                      train_parameter_dict[\"n_epochs\"],\n",
        "                      train_parameter_dict[\"data_yaml_address\"],\n",
        "                      imgsz=train_parameter_dict[\"imgsz\"],\n",
        "                      patience=train_parameter_dict[\"patience\"],\n",
        "                      device=train_parameter_dict['device'],\n",
        "                      batch=train_parameter_dict['batch'],\n",
        "                      aug_dict=augmentation_dict)\n",
        "\n",
        "print(\"Results have been saved in:\", results.save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To store final results inside drive\n",
        "shutil.move(str(results.save_dir), 'drive/MyDrive/Mhadei Restoration Research/Modelling Results/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TCF2WmRNxWme",
        "outputId": "e2137614-9d90-4325-f822-17b23ec636f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/Mhadei Restoration Research/Modelling Results/train2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rough"
      ],
      "metadata": {
        "id": "Wg1a82_PEf2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions should have worked but they don't work. Very weird. Haven't played around with them enough or tested them enough though."
      ],
      "metadata": {
        "id": "wHlvCwtwElwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### changing augmentation hyperparameters\n",
        "def change_config_yaml(default_yaml_address, param_dict, new_address):\n",
        "    create_new_config_yaml(default_yaml_address, param_dict, new_address)\n",
        "    change_default_yaml_config_address(default_yaml_address, new_address)\n",
        "    return None\n",
        "\n",
        "\n",
        "def create_new_config_yaml(source_yaml_address,\n",
        "                         param_dict,\n",
        "                         new_yaml_save_address):\n",
        "    source_yaml = open_yaml_file(source_yaml_address)\n",
        "    for param, val in param_dict.items():\n",
        "        try:\n",
        "            source_yaml[param] = val\n",
        "        except:\n",
        "            print(f\"Problem with parameter {param}\")\n",
        "\n",
        "    save_yaml_file(source_yaml, new_yaml_save_address)\n",
        "    return None\n",
        "\n",
        "\n",
        "def change_default_yaml_config_address(default_yaml_address, new_address):\n",
        "    default_yaml = open_yaml_file(default_yaml_address)\n",
        "    default_yaml['cfg'] = new_address\n",
        "    save_yaml_file(default_yaml, default_yaml_address)\n",
        "    return None\n",
        "\n",
        "\n",
        "def change_default_yaml_with_augmentation_params(config_yaml_address,\n",
        "                                                 augmentation_dict):\n",
        "\n",
        "    cfg_yaml = open_yaml_file(config_yaml_address)\n",
        "    create_true_default_config_yaml(cfg_yaml)\n",
        "\n",
        "    for augmentation_parameter, augmentation_value in augmentation_dict.items():\n",
        "        try:\n",
        "            cfg_yaml[augmentation_parameter] = augmentation_value\n",
        "        except:\n",
        "            print(f\"Problem with augementation parameter {augmentation_parameter}\")\n",
        "\n",
        "    save_yaml_file(cfg_yaml, config_yaml_address)\n",
        "    return None\n",
        "\n",
        "\n",
        "def create_true_default_config_yaml(config_yaml):\n",
        "    main_dir_files = os.listdir(\"/content/\")\n",
        "    if 'true_default.yaml' in main_dir_files:\n",
        "        return None\n",
        "    save_yaml_file(config_yaml, '/content/true_default.yaml')\n",
        "    return None"
      ],
      "metadata": {
        "id": "yrVjzcTSEhd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}